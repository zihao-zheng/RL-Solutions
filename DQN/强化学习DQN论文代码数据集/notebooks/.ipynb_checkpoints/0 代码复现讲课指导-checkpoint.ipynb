{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Atari with Deep Reinforcement Learning\n",
    "### 授课老师：Alex\n",
    "&nbsp; \n",
    "\n",
    "# 1 前言\n",
    "## 1.1课程回顾\n",
    "\n",
    "\n",
    "上节课我们讨论的内容有：\n",
    "    \n",
    "  * DQN算法模型整体概括\n",
    "  * 算法的细节处理，包括：\n",
    "      * 图像输入信息的预处理\n",
    "      * Replay Buffer\n",
    "      * Semi-Gradient Method\n",
    "  * 提到了2015年Nature的另一篇论文\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 本课知识树\n",
    "\n",
    "这有可能是同学们第一次实践深度强化学习的算法，甚至可能是第一次实践强化学习的算法，所以我们将使用比较多的时间，带着同学们把每一个步骤都过一遍，让同学们熟悉整体的流程。\n",
    "\n",
    "论文本身的难度并不是很大，算法也不是很复杂，但是还是有一些细节需要注意，到时候也会提醒大家。\n",
    "\n",
    "这节课主要的顺序是：\n",
    "\n",
    "  * 学习如何了解和使用gym提供的environment\n",
    "  * 按照论文进行预处理并使用pytorch搭建Q-Network\n",
    "  * 实现DQN算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 准备工作\n",
    "## 2.1项目环境配置\n",
    "\n",
    "以下是我使用的主要的包和版本\n",
    "\n",
    "* Python3.7\n",
    "* jupyter notebook\n",
    "* torch           1.4.0\n",
    "* numpy           1.17.0\n",
    "* gym             0.17.1\n",
    "  * gym 需要 atari 和 box2d dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 项目代码结构\n",
    "\n",
    "## 3.1 config.py\n",
    "    \n",
    "    存放所有训练需要的超参数，方便统一调参\n",
    "\n",
    "\n",
    "## 3.2 networks.py\n",
    "    \n",
    "    构建使用的神经网络类\n",
    "    \n",
    "## 3.3 utils.py\n",
    "\n",
    "    构建一些辅助性质的函数和类\n",
    "    \n",
    "## 3.4 agent.py\n",
    " \n",
    "    构建使用Deep Q-Learning的agent类\n",
    "    \n",
    "## 3.5 train_ram.py\n",
    "\n",
    "    主要训练agent的文件之一，针对RAM输入进行训练\n",
    "    \n",
    "## 3.6 train_visual.py\n",
    "\n",
    "    主要训练agent的文件之一，针对VISUAL输入进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 算法模块及细\n",
    "\n",
    "## 4.1 如何使用gym environment\n",
    "\n",
    "* 1 how to use gym.ipynb\n",
    "\n",
    "## 4.2 图像输入预处理\n",
    "\n",
    "* 2 preprocessing and network model.ipynb \n",
    "\n",
    "## 4.3 如何构建神经网络\n",
    "\n",
    "* 2 preprocessing and network model.ipynb\n",
    "\n",
    "## 4.4 储存transition并存入replay buffer\n",
    "\n",
    "* 3 Algorithm details.ipynb\n",
    "\n",
    "## 4.5 计算Q-Network的loss并更新\n",
    "\n",
    "* 3 Algorithm details.ipynb\n",
    "\n",
    "## 4.6 整体流程\n",
    "\n",
    "* Pycharam　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 代码梳理及细节回顾\n",
    "\n",
    "　　全部讲解完成之后，我们会回到pycharm中重新介绍整体结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 作业\n",
    "  \n",
    "`【思考题】`如果要将Double Q-Learning的思路放入Deep Q-Learning中，你会如何实践？\n",
    "\n",
    "`【思考题】`Preprocessing中的裁剪区域你最终如何选择？为什么？\n",
    "\n",
    "`【代码实践】`请尝试将replay buffer写成一个类，需要至少有两个方法：\n",
    "  * 1.写入数据(transition)\n",
    "  * 2.从已储存的数据随机抽样并返回，供agent使用\n",
    "  * 3.可以使用deque"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMaJPtlMHur6DonwEyZLw5h",
   "collapsed_sections": [],
   "name": "data process and load.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
