{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**目录：**\n",
    "1. 激活environment，查看基本信息\n",
    "2. 初始化environment，查看state具体信息\n",
    "3. 执行action并可视化效果\n",
    "4. 如何完成一个episode\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTsg5j62xfnk"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 激活environment，查看基本信息\n",
    "### 1)如何激活\n",
    "\n",
    "  gym激活environment的方式很简单，不过需要在官网先找到需要的environment的名字，[具体地址在这里](www.google.com)。在这个文件中，我们将展示两个environment：\n",
    "  \n",
    "  * RAM输入：LunarLander-v2\n",
    "  * VISUAL输入：Pong-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1586088546550,
     "user": {
      "displayName": "Rongfan Liao",
      "photoUrl": "",
      "userId": "07803922812103577726"
     },
     "user_tz": -480
    },
    "id": "eo9f_BRVPpcK",
    "outputId": "81a110d9-b1e7-46b6-f000-76100709da4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifengwei/anaconda3/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "#使用gym.make(name)激活一个environment\n",
    "env1 = gym.make('LunarLander-v2')\n",
    "env2 = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 查看基本信息，包括state信息的shape，action space的大小\n",
    "\n",
    "注意这里我们仅讨论discrete action space，对于continuous action space的environment等后面用到再讨论。一般来说\n",
    "\n",
    "  * env.observation_space 可以得到state信息，是一个Box类，不需要了解\n",
    "  * env.observation_space.shape 可以像numpy array那样得到state的shape\n",
    "  * env.action_space 可以得到action的信息，是一个Discrete类，不需要了解\n",
    "  * env.action_space.n 可以得到action的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(8,), gym.spaces.box.Box)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env1.observation_space, type(env1.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(210, 160, 3), gym.spaces.box.Box)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.observation_space, type(env2.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(4), gym.spaces.discrete.Discrete)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env1.action_space, type(env1.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(6), gym.spaces.discrete.Discrete)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.action_space, type(env2.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LunarLander-v2的state shape和action space大小\n",
    "env1.observation_space.shape, env1.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 160, 3), 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pong-v0的state shape和action space大小\n",
    "env2.observation_space.shape, env2.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 初始化environment，查看state具体信息\n",
    "\n",
    "想要开始和environment的交互，需要先将其进行一次初始化。初始化使用函数`env.reset()`，会返回具体的state数值信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00387831,  1.4010615 ,  0.39281964, -0.4381565 , -0.00448724,\n",
       "       -0.08897934,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state1 = env1.reset()\n",
    "state1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2 = env2.reset()\n",
    "state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 执行action并可视化效果\n",
    "\n",
    "### 1) 基本操作\n",
    "\n",
    "执行action可以使用env.step(action)来进行，这里action必须是一个valid的输入，对于discrete action space需要是一个整数\n",
    "\n",
    "env.step()函数会返回四个值，分别是\n",
    "  * 新的state\n",
    "  * action的reward\n",
    "  * action是否导致当前episode结束\n",
    "  * info信息（可忽视）\n",
    "  \n",
    "可视化则可以直接通过env.render()实现。对于VISUAL的environment，也可以使用env.render(mode='rgb_array')得到RGB的array再使用plt.imshow()进行可视化，也可以直接对state信息使用plt.imshow()可视化。可视化可以帮助我们更好地理解agent的行为，也可以更好地理解action本身的意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env1.reset()\n",
    "env1.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3747572393758105, False, {})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state, reward, done, info = env1.step(0)\n",
    "reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00425539,  0.00621867,  0.00058311, -0.02570328,  0.00482431,\n",
       "       -0.00113297,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state - state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env1.reset()\n",
    "env2.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x132b70278>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env2.reset()\n",
    "plt.imshow(env2.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12b0ccf98>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, False, {'ale.lives': 0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state, reward, done, info = env2.step(0)\n",
    "reward, done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 使用可视化帮助理解action\n",
    "\n",
    "在使用可视化帮助理解action的意义时，一般要进行多次循环才能从连续动画中看出效果，此时要注意，env.step()只有在episode没结束时有效，所以我们需要监视episode是否已经结束，具体方法参考下面的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env1.reset()\n",
    "done = False\n",
    "action = 1 # choose the action you want to understand\n",
    "t = 0\n",
    "for _ in range(1000): # 2000 steps\n",
    "    t += 1\n",
    "    env1.render() # visualize\n",
    "    state, reward, done, _ = env1.step(action)\n",
    "    if done:\n",
    "        break\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env2.reset()\n",
    "done = False\n",
    "action = 5 # choose the action you want to understand\n",
    "t = 0\n",
    "for _ in range(2000): # 2000 steps\n",
    "    t += 1\n",
    "    env2.render() # visualize\n",
    "    state, reward, done, _ = env2.step(action)\n",
    "    if done:\n",
    "        break\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 如何完成一个episode\n",
    "\n",
    "其实这个内容在刚才可视化的代码中已经基本可以看到流程了，在这里我们会忽略可视化的部分，给大家展示如何查看随机策略在多个episode下的平均reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-430.3580260653189,\n",
       " -197.18059078775065,\n",
       " -127.00510542788162,\n",
       " -269.2504180401962,\n",
       " -116.67861152765866]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = env1\n",
    "num_episode = 5\n",
    "max_t = 1000\n",
    "reward_log = []\n",
    "\n",
    "for _ in range(num_episode):\n",
    "    \n",
    "    # initialize\n",
    "    env.reset()\n",
    "    t = 0\n",
    "    episodic_reward = 0\n",
    "    \n",
    "    for t in range(max_t):\n",
    "        \n",
    "        #env.render()\n",
    "        action = env.action_space.sample() # random action\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        episodic_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    reward_log.append(episodic_reward)\n",
    "\n",
    "reward_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**最后，一个好的习惯是使用`env.close()`关闭已经激活的environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1.close()\n",
    "env2.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMaJPtlMHur6DonwEyZLw5h",
   "collapsed_sections": [],
   "name": "data process and load.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
