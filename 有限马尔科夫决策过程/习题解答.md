 ##### 习题解答

##### 练习 3.1  

​	自己设计三个符合MDP框架的任务，并确定每个任务的状态、动作和收益。这三个任务要尽可能不同。而且框架要抽象灵活，并能以多种方式进行应用。至少在其中一个任务中，尝试去突破它的限制。

>解答：1\\空调制冷时的控制：假设强化学习被用于确定空调是否进行制冷。这个应用中的动作可能是确定空调制冷或停止制冷，状态可能是传感器所探测到室内的温度及控制器设定的温度。当正确制冷或停止制冷时，收益可能为+1；而处理错误时，收益为一负值。
 2\\下围棋：假设强化学习被用于围棋，当然我们已经有了这个案例—AlphaGo。在这个应用中动作为下棋，状态为棋局，当一步棋可以使胜的概率更大时，收益可能为+1；而使胜率降低时，收益为一负值。
 3\\烤箱的温度控制：假设强化学习被用于控制烤箱的温度。这个应用中动作为设定目标温度。状态可能是热电偶，加热装置和温度控制器。收益可能是烤箱内温度与设定温度的差值。
 在这个应用中，我们可以考虑另一个定义：动作为控制器产生影响变化输出信号，这个输出信号成为操纵值，连接到加热器，控制阀或者是风扇之类的其他“最终控制元器件”，通过注入或者移除热量达到控温效果。状态为元器件的工作状态，收益仍未烤箱内温度与设定温度的差值。
##### 练习 3.2

​	MDP框架是否足以有效地表示所有目标导向的学习任务?你能给出反例吗?

>解答：不能完全表示。在MDP框架中，在每个时刻，收益都是一个**单一标量数值**，而对于目标导向的学习任务，我们的目标并非全是单一的，这也就导致我们获得的收益可能并不是单一标量，而是以向量形式返还。而对于向量形式的收益进行最大化处理显然是困难的。
例如：天气预报；我们的目标是对未来几天的天气进行一个预测，请注意，这里是未来几天而不是一天，那么针对这个目标，我们的收益就会是一个向量，代表未来几天每一天的收益值。
